<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>glitch-network (iOS fixed)</title>
<style>
  html,body { margin:0; height:100%; background:#000; overflow:hidden; }
  canvas { display:block; width:100vw; height:100vh; touch-action:none; }
  #ui {
    position:fixed; top:12px; left:50%; transform:translateX(-50%);
    background:rgba(0,0,0,.45); padding:10px 16px; border-radius:12px;
    font-family:system-ui, sans-serif; font-size:16px; color:#fff;
    border:1px solid rgba(255,255,255,.25); display:flex; gap:10px; align-items:center;
  }
  button {
    appearance:none; background:#111; border:1px solid #59f; border-radius:8px;
    color:#59f; padding:10px 20px; font-size:16px; cursor:pointer;
  }
  input[type="range"]{ width:120px; }
  #status { font-size:12px; color:#9af; opacity:.95 }
  /* Only show native controls if autoplay is blocked */
  #player { position:fixed; left:12px; bottom:12px; width:calc(100% - 24px); display:none; }
</style>
</head>
<body>
<canvas id="c"></canvas>

<div id="ui">
  <button id="fileBtn">ðŸŽµ Load / Play</button>
  <label style="display:flex;align-items:center;gap:6px;">
    Vol <input id="vol" type="range" min="0" max="1" step="0.01" value="1">
  </label>
  <span id="status"></span>
</div>

<!-- Hidden audio element (used as source; we mute it and route via WebAudio) -->
<audio id="player" playsinline></audio>

<script>
const canvas = document.getElementById("c");
const ctx = canvas.getContext("2d");
const statusEl = document.getElementById("status");
const player = document.getElementById("player");
const vol = document.getElementById("vol");

let W,H,DPR=Math.max(1,Math.min(window.devicePixelRatio||1,2));
function resize(){ W=canvas.width=innerWidth*DPR; H=canvas.height=innerHeight*DPR; }
addEventListener("resize",resize,{passive:true}); resize();

function setStatus(msg){ statusEl.textContent = msg || ""; }

// ---- iOS-safe audio path ----
let actx, analyser, dataArray, srcNode, gainNode, urlRef=null, started=false;

function ensureAudio(){
  if (actx) return;
  const AC = window.AudioContext || window.webkitAudioContext;
  actx = new AC({ latencyHint: "interactive" });

  analyser = actx.createAnalyser();
  analyser.fftSize = 512;
  dataArray = new Uint8Array(analyser.frequencyBinCount);

  gainNode = actx.createGain();
  gainNode.gain.value = +vol.value;
  gainNode.connect(actx.destination);
  vol.oninput = () => { if (gainNode) gainNode.gain.value = +vol.value; };
}

async function loadAndPlayFile(file){
  // revoke previous blob URL
  if (urlRef) { URL.revokeObjectURL(urlRef); urlRef = null; }

  ensureAudio();
  try { await actx.resume(); } catch(_) {}

  // Use <audio> as the decoder/player
  urlRef = URL.createObjectURL(file);
  player.src = urlRef;
  player.loop = true;

  // IMPORTANT: when we use MediaElementSource, the element doesn't go to speakers by itself.
  // We mute the element and route via WebAudio to the destination.
  player.muted = true;

  if (!srcNode) {
    srcNode = actx.createMediaElementSource(player);
    // Visuals tap
    srcNode.connect(analyser);
    // Audio out path
    srcNode.connect(gainNode);   // <-- this is the missing link to speakers
  }

  try {
    await player.play();
    started = true;
    setStatus("");
    // Hide native controls (weâ€™re handling playback)
    player.style.display = "none";
  } catch (e) {
    // If iOS blocks this, show native controls so user can press Play once
    player.style.display = "block";
    player.controls = true;
    setStatus("Tap Play on the control bar to start audio.");
  }
}

document.getElementById("fileBtn").onclick = () => {
  const inp = document.createElement("input");
  inp.type = "file";
  inp.accept = ".mp3,.wav,.ogg,.flac,.aac,.m4a";
  inp.onchange = () => { if (inp.files && inp.files[0]) loadAndPlayFile(inp.files[0]); };
  inp.click();
};

// If user presses Play on native controls, make sure context is running
player.addEventListener("play", async () => {
  try { await actx.resume(); } catch(_) {}
  started = true; setStatus("");
});

// ---- Visuals: glitchy architectural network ----
const N=140, nodes=[];
for(let i=0;i<N;i++){
  nodes.push({
    x:Math.random()*W, y:Math.random()*H,
    vx:(Math.random()-0.5)*2, vy:(Math.random()-0.5)*2,
    r:2+Math.random()*3
  });
}

function energy(){
  if(!started || !analyser) return 0;
  analyser.getByteFrequencyData(dataArray);
  let s=0; for (let v of dataArray) s+=v;
  return s/(dataArray.length*255);
}

function draw(){
  ctx.fillStyle = "rgba(0,0,0,0.25)";
  ctx.fillRect(0,0,W,H);

  const e = energy();
  if (!started) setStatus("Tap â€˜Load / Playâ€™ and choose a file");

  for (let n of nodes){
    if (Math.random() < 0.02 + e*0.06) {
      n.vx += (Math.random()-0.5)*10*e;
      n.vy += (Math.random()-0.5)*10*e;
      if (Math.random() < 0.003 + e*0.01) { n.x = Math.random()*W; n.y = Math.random()*H; }
    }
    n.x += n.vx; n.y += n.vy;
    if (n.x<0||n.x>W) n.vx *= -1;
    if (n.y<0||n.y>H) n.vy *= -1;

    ctx.beginPath();
    ctx.arc(n.x,n.y,n.r,0,Math.PI*2);
    ctx.fillStyle = `hsl(${180+e*200},80%,${45+e*40}%)`;
    ctx.fill();
  }

  ctx.lineWidth = 0.8 + e*2.2;
  for (let i=0;i<N;i++){
    for (let j=i+1;j<N;j++){
      const dx=nodes[i].x-nodes[j].x, dy=nodes[i].y-nodes[j].y, d=Math.hypot(dx,dy);
      const reach = 110 + e*220;
      if (d < reach){
        const a = 1 - d/(reach+1);
        ctx.strokeStyle = `rgba(180,210,255,${0.08 + a*0.5})`;
        ctx.beginPath();
        ctx.moveTo(nodes[i].x, nodes[i].y);
        const mx = (nodes[i].x + nodes[j].x)/2 + (Math.random()-0.5)*6*e;
        const my = (nodes[i].y + nodes[j].y)/2 + (Math.random()-0.5)*6*e;
        ctx.lineTo(mx, my);
        ctx.lineTo(nodes[j].x, nodes[j].y);
        ctx.stroke();
      }
    }
  }

  requestAnimationFrame(draw);
}
draw();
</script>
</body>
</html>