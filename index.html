<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>glitch-network</title>
<style>
  html,body { margin:0; height:100%; background:#000; overflow:hidden; }
  canvas { display:block; width:100vw; height:100vh; touch-action:none; }
  #ui {
    position:fixed; top:12px; left:50%; transform:translateX(-50%);
    background:rgba(0,0,0,.4); padding:10px 16px; border-radius:12px;
    font-family:sans-serif; font-size:16px; color:#fff;
    border:1px solid rgba(255,255,255,.25); display:flex; gap:10px; align-items:center;
  }
  button {
    appearance:none; background:#111; border:1px solid #59f; border-radius:8px;
    color:#59f; padding:10px 20px; font-size:16px; cursor:pointer;
  }
  #status { font-size:12px; color:#9af; opacity:.9 }
  #drop { position:fixed; inset:0; display:none; place-items:center;
    color:#9af; background:rgba(0,0,20,.7); border:2px dashed #59f;
    font-family:sans-serif; font-size:18px; }
</style>
</head>
<body>
<canvas id="c"></canvas>
<div id="ui">
  <button id="fileBtn">🎵 Load Audio</button>
  <span id="status"></span>
</div>
<div id="drop">Drop an audio file…</div>

<script>
const canvas = document.getElementById("c");
const ctx = canvas.getContext("2d");
const statusEl = document.getElementById("status");

let W,H,DPR=Math.max(1,Math.min(window.devicePixelRatio||1,2));
function resize(){ W=canvas.width=innerWidth*DPR; H=canvas.height=innerHeight*DPR; }
addEventListener("resize",resize,{passive:true}); resize();

// ---- Audio (mobile-safe) ----
let actx, analyser, dataArray, gain, currentSrc=null, started=false;

function setStatus(msg){ statusEl.textContent = msg || ""; }

function ensureAudio(){
  if (actx) return;
  const AC = window.AudioContext || window.webkitAudioContext;
  actx = new AC({ latencyHint: "interactive" });
  analyser = actx.createAnalyser();
  analyser.fftSize = 512;
  dataArray = new Uint8Array(analyser.frequencyBinCount);
  gain = actx.createGain();
  gain.gain.value = 1.0;
  gain.connect(actx.destination);
}

async function startFromFile(file){
  ensureAudio();
  // iOS/Android need resume() inside gesture path (we're in a click handler)
  try { await actx.resume(); } catch(e){ setStatus("Resume failed: "+e.message); }

  // stop previous source if any
  if (currentSrc) {
    try { currentSrc.stop(); } catch(_) {}
    try { currentSrc.disconnect(); } catch(_) {}
    currentSrc = null;
  }

  try {
    const buf = await file.arrayBuffer();
    const audio = await actx.decodeAudioData(buf);
    const src = actx.createBufferSource();
    src.buffer = audio;
    src.loop = true;

    // Tee to analyser (visuals) and to speakers (via gain)
    src.connect(analyser);
    src.connect(gain);

    src.start(0);
    currentSrc = src;
    started = true;
    setStatus(""); // clear any “tap to enable” hints
  } catch (e) {
    setStatus("Audio load error: " + (e && e.message || e));
  }
}

// File picker button (mobile-friendly)
document.getElementById("fileBtn").onclick = () => {
  const inp = document.createElement("input");
  inp.type = "file";
  inp.accept = ".mp3,.wav,.ogg,.flac,.aac,.m4a";
  inp.onchange = (e) => { if (inp.files && inp.files[0]) startFromFile(inp.files[0]); };
  inp.click();
};

// Optional desktop drag & drop (ignored on mobile)
const drop = document.getElementById("drop"); let dragCount=0;
addEventListener("dragenter",e=>{e.preventDefault();dragCount++;drop.style.display="grid";});
addEventListener("dragleave",e=>{e.preventDefault();dragCount=Math.max(0,dragCount-1);if(!dragCount)drop.style.display="none";});
addEventListener("dragover",e=>e.preventDefault());
addEventListener("drop",e=>{
  e.preventDefault();dragCount=0;drop.style.display="none";
  const f=e.dataTransfer.files && e.dataTransfer.files[0];
  if (f) startFromFile(f);
});

// ---- Particles (glitchy architectural network) ----
const N=140, nodes=[];
for(let i=0;i<N;i++){
  nodes.push({
    x:Math.random()*W, y:Math.random()*H,
    vx:(Math.random()-0.5)*2, vy:(Math.random()-0.5)*2,
    r:2+Math.random()*3
  });
}

function audioEnergy(){
  if(!started || !analyser) return 0;
  analyser.getByteFrequencyData(dataArray);
  let sum=0; for (let v of dataArray) sum+=v;
  return sum/(dataArray.length*255); // 0..1
}

function draw(){
  // subtle trails
  ctx.fillStyle = "rgba(0,0,0,0.25)";
  ctx.fillRect(0,0,W,H);

  if (actx && actx.state !== "running") setStatus("Tap ‘Load Audio’ and select a file");

  const energy = audioEnergy();

  // “glitch” bursts: random kicks + occasional teleports
  for(let n of nodes){
    if (Math.random() < 0.02 + energy*0.06) {
      n.vx += (Math.random()-0.5)*10*energy;
      n.vy += (Math.random()-0.5)*10*energy;
      if (Math.random() < 0.003 + energy*0.01) { // rare teleport
        n.x = Math.random()*W; n.y = Math.random()*H;
      }
    }

    n.x += n.vx; n.y += n.vy;
    if (n.x<0||n.x>W) n.vx*=-1;
    if (n.y<0||n.y>H) n.vy*=-1;

    // nodes
    ctx.beginPath();
    ctx.arc(n.x,n.y,n.r,0,Math.PI*2);
    ctx.fillStyle = `hsl(${180+energy*200},80%,${45+energy*40}%)`;
    ctx.fill();
  }

  // edges (architectural scaffolding)
  ctx.lineWidth = 0.8 + energy*2.2;
  for(let i=0;i<N;i++){
    for(let j=i+1;j<N;j++){
      const dx = nodes[i].x - nodes[j].x;
      const dy = nodes[i].y - nodes[j].y;
      const d  = Math.hypot(dx,dy);
      const reach = 110 + energy*220; // connect radius grows with energy
      if (d < reach){
        const a = 1 - d/(reach+1);
        ctx.strokeStyle = `rgba(180,210,255,${0.08 + a*0.5})`;
        ctx.beginPath();
        ctx.moveTo(nodes[i].x, nodes[i].y);
        // slight mid-segment jitter to feel “glitchy”
        const mx = (nodes[i].x + nodes[j].x)/2 + (Math.random()-0.5)*6*energy;
        const my = (nodes[i].y + nodes[j].y)/2 + (Math.random()-0.5)*6*energy;
        ctx.lineTo(mx, my);
        ctx.lineTo(nodes[j].x, nodes[j].y);
        ctx.stroke();
      }
    }
  }

  requestAnimationFrame(draw);
}
draw();
</script>
</body>
</html>